# -*- coding: utf-8 -*-
"""image classification with tf lite.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11EuZFz9yh0zcMXu8LBxaspP8X0tDhqcz

#**Proyek Image Classification with Tensorflow Lite**
"""

!pip install -q kaggle

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

!kaggle datasets download -d puneet6060/intel-image-classification

!unzip intel-image-classification.zip

!pip install split-folders
import splitfolders

splitfolders.ratio('/content/seg_train/seg_train', output="output", seed=42, ratio=(0.8,0.2), group_prefix=None)

import os
import pandas as pd

train_files = '/content/output/train'
val_files = '/content/output/val'
pd.DataFrame(os.listdir(train_files), columns=['Files'])

directories = os.listdir(train_files)
print(directories)
total_images = 0;

for name in directories:
  path = os.path.join(train_files, name)
  if os.path.isdir(path):
    print(f"Total {name} images: ", len(os.listdir(path)))
    total_images += len(os.listdir(path))
print('Total images: ', total_images)

train_data_dir = train_files
val_data_dir = val_files
batch_size = 32
target_size = (150, 150)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale = 1.0/255,
    rotation_range = 30,
    zoom_range = 0.2,
    vertical_flip = True,
    shear_range = 0.2,
    fill_mode = 'nearest'
    )

val_datagen = ImageDataGenerator(
    rescale = 1.0/255
    )

train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    batch_size = batch_size,
    class_mode = 'categorical',
    target_size = target_size
)

val_generator = val_datagen.flow_from_directory(
    val_data_dir,
    batch_size = batch_size,
    class_mode = 'categorical',
    target_size = target_size
)

from tensorflow import keras
from tensorflow.keras import models, layers
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Conv2D, MaxPooling2D

pre_trained_model = MobileNetV2(weights='imagenet', include_top=False,
                                input_tensor=Input(shape=(150, 150, 3))
                                )

for layer in pre_trained_model.layers:
  layer.trainable = False

model = Sequential()
model.add(pre_trained_model)
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D(2, 2))
model.add(Flatten(name='flatten'))
model.add(Dropout(0.5))
model.add(Dense(32, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(6, activation='softmax'))

model.summary()

from tensorflow.keras.callbacks import EarlyStopping
import tensorflow as tf

class stop(tf.keras.callbacks.Callback):
  def __init__(self, target_acc):
    super(stop, self).__init__()
    self.target_acc = target_acc

  def on_epoch_end(self, epoch, logs={}):
    if logs.get('accuracy') >= self.target_acc and logs.get('val_accuracy') >= self.target_acc:
      print(f'\nMencapai target akurasi {self.target_acc}% untuk training dan validation')
      self.model.stop_training = True

callbacks = stop(target_acc=0.81)
early_stopping = EarlyStopping(monitor='val_loss', mode='min', min_delta=0.1, patience=10, restore_best_weights=True)

optimizer = tf.optimizers.Adam(learning_rate = 1e-4)
model.compile(
    optimizer=optimizer,
    loss = 'categorical_crossentropy',
    metrics=['accuracy']
)

hist = model.fit(train_generator, epochs = 15,
                 validation_data = val_generator, callbacks = [callbacks, early_stopping])

import matplotlib.pyplot as plt

plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.title('Plot Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='lower right')
plt.show()

plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('Plot Loss Model')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper right')
plt.show()

import numpy as np

def predictions(image, model, class_names):
  images, labels = next(image)

  class_labels = list(image.class_indices.keys())
  class_names = list(class_names)

  pred = model.predict(images)
  pred_labels = np.argmax(pred, axis=1)

  num_image = len(images)
  num_rows = num_image // 4 + (num_image % 4 > 0)
  plt.figure(figsize=(18, 5 * num_rows))

  for n, i in enumerate(range(num_image)):
    true_label = class_labels[np.argmax(labels[i])]
    pred_label = class_names[pred_labels[i]]

    plt.subplot(num_rows, 4, n + 1)
    plt.imshow(images[i])
    plt.title(f'True: {true_label}\nPredicted: {pred_label}')
    plt.axis('off')

  plt.show()

class_names = train_generator.class_indices.keys()

predictions(val_generator, model, class_names)

import pathlib

export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)

converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('image_view.tflite')
tflite_model_file.write_bytes(tflite_model)